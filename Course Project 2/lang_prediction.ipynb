{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from scipy.stats import randint\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"^Unlike other reduction functions.*\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\") \n",
    "authors = pd.read_csv(\"authors.csv\") \n",
    "categories = pd.read_csv(\"categories.csv\") \n",
    "formats = pd.read_csv(\"formats.csv\") \n",
    "places = pd.read_csv(\"places.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>bestsellers-rank</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "      <th>dimension-x</th>\n",
       "      <th>dimension-y</th>\n",
       "      <th>dimension-z</th>\n",
       "      <th>edition</th>\n",
       "      <th>edition-statement</th>\n",
       "      <th>for-ages</th>\n",
       "      <th>...</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>lang</th>\n",
       "      <th>publication-date</th>\n",
       "      <th>publication-place</th>\n",
       "      <th>rating-avg</th>\n",
       "      <th>rating-count</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1]</td>\n",
       "      <td>49848.0</td>\n",
       "      <td>[214, 220, 237, 2646, 2647, 2659, 2660, 2679]</td>\n",
       "      <td>SOLDIER FIVE is an elite soldier's explosive m...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>184018907X</td>\n",
       "      <td>9781840189070</td>\n",
       "      <td>en</td>\n",
       "      <td>2004-10-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.03</td>\n",
       "      <td>292.0</td>\n",
       "      <td>Soldier Five : The Real Truth About The Bravo ...</td>\n",
       "      <td>/Soldier-Five-Mike-Coburn/9781840189070</td>\n",
       "      <td>224.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>115215.0</td>\n",
       "      <td>[235, 3386]</td>\n",
       "      <td>John Moran and Carl Williams were the two bigg...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>203.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>184454737X</td>\n",
       "      <td>9781844547371</td>\n",
       "      <td>en</td>\n",
       "      <td>2009-03-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.60</td>\n",
       "      <td>335.0</td>\n",
       "      <td>Underbelly : The Gangland War</td>\n",
       "      <td>/Underbelly-Andrew-Rule/9781844547371</td>\n",
       "      <td>285.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[4]</td>\n",
       "      <td>11732.0</td>\n",
       "      <td>[358, 2630, 360, 2632]</td>\n",
       "      <td>Sir Phillip knew that Eloise Bridgerton was a ...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>New edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8416327866</td>\n",
       "      <td>9788416327867</td>\n",
       "      <td>es</td>\n",
       "      <td>2020-04-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.88</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>A Sir Phillip, Con Amor</td>\n",
       "      <td>/Sir-Phillip-Con-Amor-Julia-Quinn/9788416327867</td>\n",
       "      <td>386.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[5, 6, 7, 8]</td>\n",
       "      <td>114379.0</td>\n",
       "      <td>[377, 2978, 2980]</td>\n",
       "      <td>The Third Book of General Ignorance  gathers t...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Export - Airside ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>571308996</td>\n",
       "      <td>9780571308996</td>\n",
       "      <td>en</td>\n",
       "      <td>2015-10-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.17</td>\n",
       "      <td>384.0</td>\n",
       "      <td>QI: The Third Book of General Ignorance</td>\n",
       "      <td>/QI-Third-Book-General-Ignorance-John-Lloyd/97...</td>\n",
       "      <td>436.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[9]</td>\n",
       "      <td>98413.0</td>\n",
       "      <td>[2813, 2980]</td>\n",
       "      <td>The Try Guys deliver their first book-an inspi...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>8352518</td>\n",
       "      <td>9780008352516</td>\n",
       "      <td>en</td>\n",
       "      <td>2019-06-18 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5095.0</td>\n",
       "      <td>The Hidden Power of F*cking Up</td>\n",
       "      <td>/Hidden-Power-F-cking-Up-Try-Guys/9780008352516</td>\n",
       "      <td>980.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        authors  bestsellers-rank  \\\n",
       "0           [1]           49848.0   \n",
       "1        [2, 3]          115215.0   \n",
       "2           [4]           11732.0   \n",
       "3  [5, 6, 7, 8]          114379.0   \n",
       "4           [9]           98413.0   \n",
       "\n",
       "                                      categories  \\\n",
       "0  [214, 220, 237, 2646, 2647, 2659, 2660, 2679]   \n",
       "1                                    [235, 3386]   \n",
       "2                         [358, 2630, 360, 2632]   \n",
       "3                              [377, 2978, 2980]   \n",
       "4                                   [2813, 2980]   \n",
       "\n",
       "                                         description  dimension-x  \\\n",
       "0  SOLDIER FIVE is an elite soldier's explosive m...        129.0   \n",
       "1  John Moran and Carl Williams were the two bigg...        127.0   \n",
       "2  Sir Phillip knew that Eloise Bridgerton was a ...        150.0   \n",
       "3  The Third Book of General Ignorance  gathers t...        153.0   \n",
       "4  The Try Guys deliver their first book-an inspi...        191.0   \n",
       "\n",
       "   dimension-y  dimension-z      edition    edition-statement for-ages  ...  \\\n",
       "0        198.0         20.0          NaN                  NaN      NaN  ...   \n",
       "1        203.2         25.4          NaN                  NaN      NaN  ...   \n",
       "2        224.0         28.0  New edition                  NaN      NaN  ...   \n",
       "3        234.0         24.0          NaN  Export - Airside ed      NaN  ...   \n",
       "4        240.0         29.0          NaN                  NaN      NaN  ...   \n",
       "\n",
       "       isbn10         isbn13 lang     publication-date publication-place  \\\n",
       "0  184018907X  9781840189070   en  2004-10-14 00:00:00               NaN   \n",
       "1  184454737X  9781844547371   en  2009-03-13 00:00:00               NaN   \n",
       "2  8416327866  9788416327867   es  2020-04-30 00:00:00               NaN   \n",
       "3   571308996  9780571308996   en  2015-10-01 00:00:00               NaN   \n",
       "4     8352518  9780008352516   en  2019-06-18 00:00:00               NaN   \n",
       "\n",
       "  rating-avg rating-count                                              title  \\\n",
       "0       4.03        292.0  Soldier Five : The Real Truth About The Bravo ...   \n",
       "1       3.60        335.0                      Underbelly : The Gangland War   \n",
       "2       3.88      37211.0                            A Sir Phillip, Con Amor   \n",
       "3       4.17        384.0            QI: The Third Book of General Ignorance   \n",
       "4       3.90       5095.0                     The Hidden Power of F*cking Up   \n",
       "\n",
       "                                                 url  weight  \n",
       "0            /Soldier-Five-Mike-Coburn/9781840189070  224.00  \n",
       "1              /Underbelly-Andrew-Rule/9781844547371  285.76  \n",
       "2    /Sir-Phillip-Con-Amor-Julia-Quinn/9788416327867  386.00  \n",
       "3  /QI-Third-Book-General-Ignorance-John-Lloyd/97...  436.00  \n",
       "4    /Hidden-Power-F-cking-Up-Try-Guys/9780008352516  980.00  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9561</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>451324</td>\n",
       "      <td># House Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>454250</td>\n",
       "      <td># Petal Press</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>249724</td>\n",
       "      <td>#GARCIA MIGUELE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>287710</td>\n",
       "      <td>#Worldlcass Media</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   author_id        author_name\n",
       "0       9561                NaN\n",
       "1     451324      # House Press\n",
       "2     454250      # Petal Press\n",
       "3     249724    #GARCIA MIGUELE\n",
       "4     287710  #Worldlcass Media"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>.Net Programming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>176</td>\n",
       "      <td>20th Century &amp; Contemporary Classical Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3291</td>\n",
       "      <td>20th Century &amp; Contemporary Classical Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2659</td>\n",
       "      <td>20th Century History: C 1900  To C 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2661</td>\n",
       "      <td>21st Century History: From C 2000 -</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category_id                                category_name\n",
       "0         1998                             .Net Programming\n",
       "1          176  20th Century & Contemporary Classical Music\n",
       "2         3291  20th Century & Contemporary Classical Music\n",
       "3         2659      20th Century History: C 1900  To C 2000\n",
       "4         2661          21st Century History: From C 2000 -"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format_id</th>\n",
       "      <th>format_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>Address</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>Bath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Big</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Board</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   format_id format_name\n",
       "0         21     Address\n",
       "1          5       Audio\n",
       "2         27        Bath\n",
       "3         44         Big\n",
       "4         14       Board"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "formats.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert a list of ids to a list of names using the mappings\n",
    "def id_to_name(id_list, mapping):\n",
    "  # Convert the id_list from string to list\n",
    "  id_list = eval(id_list)\n",
    "  # Initialize an empty list to store the names\n",
    "  name_list = []\n",
    "  # Loop through each id in the id_list\n",
    "  for id in id_list:\n",
    "    # Try to find the corresponding name in the mapping using the id as the key\n",
    "    try:\n",
    "      name = mapping[id]\n",
    "    # If the id is not found, catch the KeyError exception and assign a default value of null\n",
    "    except KeyError:\n",
    "      name = 'null'\n",
    "    # Append the name to the name_list\n",
    "    name_list.append(name)\n",
    "  # Return the name_list as a string\n",
    "  return str(name_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create new columns for authors_name, categories_name, and format_name using the id_to_name function and the mappings\n",
    "dataset['authors_name'] = dataset['authors'].apply(lambda x: id_to_name(x, authors['author_name']))\n",
    "dataset['categories_name'] = dataset['categories'].apply(lambda x: id_to_name(x, categories['category_name']))\n",
    "\n",
    "# Drop the original columns for authors, categories, and format\n",
    "dataset = dataset.drop(['authors', 'categories'], axis=1)\n",
    "\n",
    "# Merge the main dataset and the format file on the format and format_id columns using a left join\n",
    "dataset = pd.merge(dataset, formats, how='left', left_on='format', right_on='format_id')\n",
    "\n",
    "# Rename the format_name column to format_name\n",
    "dataset = dataset.rename(columns={'format_name': 'format_name'})\n",
    "\n",
    "# Drop the original format and format_id columns\n",
    "dataset = dataset.drop(['format', 'format_id'], axis=1)\n",
    "\n",
    "# Save the modified dataset\n",
    "# dataset.to_csv('dataset_modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bestsellers-rank</th>\n",
       "      <th>description</th>\n",
       "      <th>dimension-x</th>\n",
       "      <th>dimension-y</th>\n",
       "      <th>dimension-z</th>\n",
       "      <th>edition</th>\n",
       "      <th>edition-statement</th>\n",
       "      <th>for-ages</th>\n",
       "      <th>id</th>\n",
       "      <th>illustrations-note</th>\n",
       "      <th>...</th>\n",
       "      <th>publication-date</th>\n",
       "      <th>publication-place</th>\n",
       "      <th>rating-avg</th>\n",
       "      <th>rating-count</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>weight</th>\n",
       "      <th>authors_name</th>\n",
       "      <th>categories_name</th>\n",
       "      <th>format_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49848.0</td>\n",
       "      <td>SOLDIER FIVE is an elite soldier's explosive m...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9781840189070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2004-10-14 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.03</td>\n",
       "      <td>292.0</td>\n",
       "      <td>Soldier Five : The Real Truth About The Bravo ...</td>\n",
       "      <td>/Soldier-Five-Mike-Coburn/9781840189070</td>\n",
       "      <td>224.00</td>\n",
       "      <td>['# House Press']</td>\n",
       "      <td>['Aviation &amp; Space Medicine', 'Baby Books', 'B...</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115215.0</td>\n",
       "      <td>John Moran and Carl Williams were the two bigg...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>203.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9781844547371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2009-03-13 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.60</td>\n",
       "      <td>335.0</td>\n",
       "      <td>Underbelly : The Gangland War</td>\n",
       "      <td>/Underbelly-Andrew-Rule/9781844547371</td>\n",
       "      <td>285.76</td>\n",
       "      <td>['# Petal Press', '#GARCIA MIGUELE']</td>\n",
       "      <td>['Baptist Churches', 'null']</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11732.0</td>\n",
       "      <td>Sir Phillip knew that Eloise Bridgerton was a ...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>New edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9788416327867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-04-30 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.88</td>\n",
       "      <td>37211.0</td>\n",
       "      <td>A Sir Phillip, Con Amor</td>\n",
       "      <td>/Sir-Phillip-Con-Amor-Julia-Quinn/9788416327867</td>\n",
       "      <td>386.00</td>\n",
       "      <td>['#Worldlcass Media']</td>\n",
       "      <td>['Cartoons &amp; Comic Strips', 'True Stories for ...</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114379.0</td>\n",
       "      <td>The Third Book of General Ignorance  gathers t...</td>\n",
       "      <td>153.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Export - Airside ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9780571308996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2015-10-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.17</td>\n",
       "      <td>384.0</td>\n",
       "      <td>QI: The Third Book of General Ignorance</td>\n",
       "      <td>/QI-Third-Book-General-Ignorance-John-Lloyd/97...</td>\n",
       "      <td>436.00</td>\n",
       "      <td>['#shakeback Publishing', '&amp;  Rueckert  Elkins...</td>\n",
       "      <td>['Chakras, Auras &amp; Spiritual Energy', 'null', ...</td>\n",
       "      <td>Paperback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98413.0</td>\n",
       "      <td>The Try Guys deliver their first book-an inspi...</td>\n",
       "      <td>191.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9780008352516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2019-06-18 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5095.0</td>\n",
       "      <td>The Hidden Power of F*cking Up</td>\n",
       "      <td>/Hidden-Power-F-cking-Up-Try-Guys/9780008352516</td>\n",
       "      <td>980.00</td>\n",
       "      <td>['&amp; Bonchek Shepsle &amp; Bonchek']</td>\n",
       "      <td>['null', 'null']</td>\n",
       "      <td>Hardback</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   bestsellers-rank                                        description  \\\n",
       "0           49848.0  SOLDIER FIVE is an elite soldier's explosive m...   \n",
       "1          115215.0  John Moran and Carl Williams were the two bigg...   \n",
       "2           11732.0  Sir Phillip knew that Eloise Bridgerton was a ...   \n",
       "3          114379.0  The Third Book of General Ignorance  gathers t...   \n",
       "4           98413.0  The Try Guys deliver their first book-an inspi...   \n",
       "\n",
       "   dimension-x  dimension-y  dimension-z      edition    edition-statement  \\\n",
       "0        129.0        198.0         20.0          NaN                  NaN   \n",
       "1        127.0        203.2         25.4          NaN                  NaN   \n",
       "2        150.0        224.0         28.0  New edition                  NaN   \n",
       "3        153.0        234.0         24.0          NaN  Export - Airside ed   \n",
       "4        191.0        240.0         29.0          NaN                  NaN   \n",
       "\n",
       "  for-ages             id illustrations-note  ...     publication-date  \\\n",
       "0      NaN  9781840189070                NaN  ...  2004-10-14 00:00:00   \n",
       "1      NaN  9781844547371                NaN  ...  2009-03-13 00:00:00   \n",
       "2      NaN  9788416327867                NaN  ...  2020-04-30 00:00:00   \n",
       "3      NaN  9780571308996                NaN  ...  2015-10-01 00:00:00   \n",
       "4      NaN  9780008352516                NaN  ...  2019-06-18 00:00:00   \n",
       "\n",
       "  publication-place rating-avg rating-count  \\\n",
       "0               NaN       4.03        292.0   \n",
       "1               NaN       3.60        335.0   \n",
       "2               NaN       3.88      37211.0   \n",
       "3               NaN       4.17        384.0   \n",
       "4               NaN       3.90       5095.0   \n",
       "\n",
       "                                               title  \\\n",
       "0  Soldier Five : The Real Truth About The Bravo ...   \n",
       "1                      Underbelly : The Gangland War   \n",
       "2                            A Sir Phillip, Con Amor   \n",
       "3            QI: The Third Book of General Ignorance   \n",
       "4                     The Hidden Power of F*cking Up   \n",
       "\n",
       "                                                 url  weight  \\\n",
       "0            /Soldier-Five-Mike-Coburn/9781840189070  224.00   \n",
       "1              /Underbelly-Andrew-Rule/9781844547371  285.76   \n",
       "2    /Sir-Phillip-Con-Amor-Julia-Quinn/9788416327867  386.00   \n",
       "3  /QI-Third-Book-General-Ignorance-John-Lloyd/97...  436.00   \n",
       "4    /Hidden-Power-F-cking-Up-Try-Guys/9780008352516  980.00   \n",
       "\n",
       "                                        authors_name  \\\n",
       "0                                  ['# House Press']   \n",
       "1               ['# Petal Press', '#GARCIA MIGUELE']   \n",
       "2                              ['#Worldlcass Media']   \n",
       "3  ['#shakeback Publishing', '&  Rueckert  Elkins...   \n",
       "4                    ['& Bonchek Shepsle & Bonchek']   \n",
       "\n",
       "                                     categories_name  format_name  \n",
       "0  ['Aviation & Space Medicine', 'Baby Books', 'B...    Paperback  \n",
       "1                       ['Baptist Churches', 'null']    Paperback  \n",
       "2  ['Cartoons & Comic Strips', 'True Stories for ...    Paperback  \n",
       "3  ['Chakras, Auras & Spiritual Energy', 'null', ...    Paperback  \n",
       "4                                   ['null', 'null']     Hardback  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 1109383 rows and 28 columns.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has\", dataset.shape[0], \"rows and\", dataset.shape[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The columns and their data types are:\n",
      "bestsellers-rank      float64\n",
      "description            object\n",
      "dimension-x           float64\n",
      "dimension-y           float64\n",
      "dimension-z           float64\n",
      "edition                object\n",
      "edition-statement      object\n",
      "for-ages               object\n",
      "id                      int64\n",
      "illustrations-note     object\n",
      "image-checksum         object\n",
      "image-path             object\n",
      "image-url              object\n",
      "imprint                object\n",
      "index-date            float64\n",
      "isbn10                 object\n",
      "isbn13                  int64\n",
      "lang                   object\n",
      "publication-date       object\n",
      "publication-place     float64\n",
      "rating-avg            float64\n",
      "rating-count          float64\n",
      "title                  object\n",
      "url                    object\n",
      "weight                float64\n",
      "authors_name           object\n",
      "categories_name        object\n",
      "format_name            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"The columns and their data types are:\") \n",
    "print(dataset.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in each column are:\n",
      "bestsellers-rank       466842\n",
      "description             80087\n",
      "dimension-x             48227\n",
      "dimension-y             93531\n",
      "dimension-z             48227\n",
      "edition                926569\n",
      "edition-statement      747261\n",
      "for-ages              1033390\n",
      "id                          0\n",
      "illustrations-note     752907\n",
      "image-checksum             27\n",
      "image-path                 27\n",
      "image-url                  27\n",
      "imprint                830049\n",
      "index-date            1109383\n",
      "isbn10                      0\n",
      "isbn13                      0\n",
      "lang                    60407\n",
      "publication-date         2603\n",
      "publication-place     1109383\n",
      "rating-avg             440130\n",
      "rating-count           440130\n",
      "title                       0\n",
      "url                         0\n",
      "weight                  87173\n",
      "authors_name                0\n",
      "categories_name             0\n",
      "format_name              6622\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The number of null values in each column are:\") \n",
    "print(dataset.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The summary of each column is:\n",
      "       bestsellers-rank   dimension-x   dimension-y   dimension-z  \\\n",
      "count      6.425410e+05  1.061156e+06  1.015852e+06  1.061156e+06   \n",
      "mean       9.209777e+05  1.607659e+02  2.249102e+02  2.644117e+01   \n",
      "std        8.642210e+05  3.802671e+01  4.347322e+01  4.779869e+01   \n",
      "min        1.001000e+03  2.500000e-01  1.000000e+00  1.000000e-01   \n",
      "25%        1.654890e+05  1.380000e+02  2.030000e+02  9.000000e+00   \n",
      "50%        6.646830e+05  1.520000e+02  2.290000e+02  1.575000e+01   \n",
      "75%        1.455812e+06  1.780000e+02  2.420000e+02  2.500000e+01   \n",
      "max        3.679776e+06  3.871000e+03  2.000000e+03  2.000000e+03   \n",
      "\n",
      "                 id  index-date        isbn13  publication-place  \\\n",
      "count  1.109383e+06         0.0  1.109383e+06                0.0   \n",
      "mean   9.781658e+12         NaN  9.781658e+12                NaN   \n",
      "std    1.747523e+09         NaN  1.747523e+09                NaN   \n",
      "min    9.780000e+12         NaN  9.780000e+12                NaN   \n",
      "25%    9.780801e+12         NaN  9.780801e+12                NaN   \n",
      "50%    9.781474e+12         NaN  9.781474e+12                NaN   \n",
      "75%    9.781743e+12         NaN  9.781743e+12                NaN   \n",
      "max    9.798389e+12         NaN  9.798389e+12                NaN   \n",
      "\n",
      "          rating-avg  rating-count        weight  \n",
      "count  669253.000000  6.692530e+05  1.022210e+06  \n",
      "mean        3.974918  1.239215e+04  4.616623e+02  \n",
      "std         0.543605  1.333263e+05  6.587618e+02  \n",
      "min         1.000000  1.000000e+00  1.500000e+01  \n",
      "25%         3.730000  5.000000e+00  1.814400e+02  \n",
      "50%         4.000000  3.900000e+01  3.180000e+02  \n",
      "75%         4.260000  5.200000e+02  5.352400e+02  \n",
      "max         5.000000  7.377337e+06  8.252200e+04  \n"
     ]
    }
   ],
   "source": [
    "print(\"The summary of each column is:\") \n",
    "print(dataset.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation matrix of the dataset is:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nawal\\AppData\\Local\\Temp\\ipykernel_39900\\4139693356.py:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  print(dataset.corr())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   bestsellers-rank  dimension-x  dimension-y  dimension-z  \\\n",
      "bestsellers-rank           1.000000     0.060753     0.052163     0.032632   \n",
      "dimension-x                0.060753     1.000000     0.804573     0.129267   \n",
      "dimension-y                0.052163     0.804573     1.000000     0.022752   \n",
      "dimension-z                0.032632     0.129267     0.022752     1.000000   \n",
      "id                         0.181542     0.024287     0.037383     0.128227   \n",
      "index-date                      NaN          NaN          NaN          NaN   \n",
      "isbn13                     0.181542     0.024287     0.037383     0.128227   \n",
      "publication-place               NaN          NaN          NaN          NaN   \n",
      "rating-avg                -0.103340     0.051849     0.043008     0.026560   \n",
      "rating-count              -0.054883    -0.050008    -0.046098     0.014729   \n",
      "weight                     0.059017     0.240304     0.249185     0.169369   \n",
      "\n",
      "                         id  index-date    isbn13  publication-place  \\\n",
      "bestsellers-rank   0.181542         NaN  0.181542                NaN   \n",
      "dimension-x        0.024287         NaN  0.024287                NaN   \n",
      "dimension-y        0.037383         NaN  0.037383                NaN   \n",
      "dimension-z        0.128227         NaN  0.128227                NaN   \n",
      "id                 1.000000         NaN  1.000000                NaN   \n",
      "index-date              NaN         NaN       NaN                NaN   \n",
      "isbn13             1.000000         NaN  1.000000                NaN   \n",
      "publication-place       NaN         NaN       NaN                NaN   \n",
      "rating-avg         0.014703         NaN  0.014703                NaN   \n",
      "rating-count       0.015518         NaN  0.015518                NaN   \n",
      "weight             0.063496         NaN  0.063496                NaN   \n",
      "\n",
      "                   rating-avg  rating-count    weight  \n",
      "bestsellers-rank    -0.103340     -0.054883  0.059017  \n",
      "dimension-x          0.051849     -0.050008  0.240304  \n",
      "dimension-y          0.043008     -0.046098  0.249185  \n",
      "dimension-z          0.026560      0.014729  0.169369  \n",
      "id                   0.014703      0.015518  0.063496  \n",
      "index-date                NaN           NaN       NaN  \n",
      "isbn13               0.014703      0.015518  0.063496  \n",
      "publication-place         NaN           NaN       NaN  \n",
      "rating-avg           1.000000      0.016926  0.075306  \n",
      "rating-count         0.016926      1.000000 -0.014648  \n",
      "weight               0.075306     -0.014648  1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"The correlation matrix of the dataset is:\") \n",
    "print(dataset.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna(subset=['lang'])\n",
    "\n",
    "# dataset = dataset.drop(['image-checksum'], axis=1)\n",
    "# dataset = dataset.drop(['image-path'], axis=1)\n",
    "# dataset = dataset.drop(['image-url'], axis=1)\n",
    "# dataset = dataset.drop(['index-date'], axis=1)\n",
    "# dataset = dataset.drop(['publication-date'], axis=1)\n",
    "# dataset = dataset.drop(['publication-place'], axis=1)\n",
    "# dataset = dataset.drop(['url'], axis=1)\n",
    "# dataset = dataset.drop(['title'], axis=1)   \n",
    "# dataset = dataset.drop(['description'], axis=1)\n",
    "# dataset = dataset.drop(['id'], axis=1)\n",
    "# dataset = dataset.drop(['edition'], axis=1)\n",
    "# dataset = dataset.drop(['edition-statement'], axis=1)\n",
    "# dataset = dataset.drop(['for-ages'], axis=1)\n",
    "# dataset = dataset.drop(['illustrations-note'], axis=1)\n",
    "# dataset = dataset.drop(['imprint'], axis=1)\n",
    "dataset = dataset.drop(['rating-avg'], axis=1)\n",
    "dataset = dataset.drop(['rating-count'], axis=1)\n",
    "dataset = dataset.drop(['bestsellers-rank'], axis=1)\n",
    "\n",
    "\n",
    "# Fill NaN values with the mean of the column\n",
    "dataset['dimension-x'].fillna(dataset['dimension-x'].mean(), inplace=True)\n",
    "dataset['dimension-x'] = dataset['dimension-x'].replace([np.inf, -np.inf], np.nan)\n",
    "dataset['dimension-x'].fillna(dataset['dimension-x'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "dataset['dimension-y'].fillna(dataset['dimension-y'].mean(), inplace=True)\n",
    "dataset['dimension-y'] = dataset['dimension-y'].replace([np.inf, -np.inf], np.nan)\n",
    "dataset['dimension-y'].fillna(dataset['dimension-y'].mean(), inplace=True)\n",
    "\n",
    "dataset['dimension-z'].fillna(dataset['dimension-z'].mean(), inplace=True)\n",
    "dataset['dimension-z'] = dataset['dimension-z'].replace([np.inf, -np.inf], np.nan)\n",
    "dataset['dimension-z'].fillna(dataset['dimension-z'].mean(), inplace=True)\n",
    "\n",
    "dataset['weight'].fillna(dataset['weight'].mean(), inplace=True)\n",
    "dataset['weight'] = dataset['weight'].replace([np.inf, -np.inf], np.nan)\n",
    "dataset['weight'].fillna(dataset['weight'].mean(), inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in each column are:\n",
      "bestsellers-rank    415869\n",
      "dimension-x              0\n",
      "dimension-y              0\n",
      "dimension-z              0\n",
      "isbn10                   0\n",
      "isbn13                   0\n",
      "lang                     0\n",
      "rating-avg          396083\n",
      "rating-count        396083\n",
      "weight               48649\n",
      "authors_name             0\n",
      "categories_name          0\n",
      "format_name           2027\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of null values in each column are:\") \n",
    "print(dataset.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop('lang', axis=1), dataset['lang'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Define numerical attributes and scaler\n",
    "num_attrs = ['dimension-x', 'dimension-y', 'dimension-z', 'weight']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Define categorical attributes and encoder\n",
    "cat_attrs = ['authors_name', 'categories_name', 'format_name', 'isbn10', 'isbn13']\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Define column transformer to apply different transformations to different columns\n",
    "col_transformer = ColumnTransformer([\n",
    "    ('num', scaler, num_attrs),\n",
    "    ('cat', encoder, cat_attrs),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classification models\n",
    "log_reg = LogisticRegression()\n",
    "dtree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define pipelines to chain together preprocessing and classifier\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('log_reg', log_reg)\n",
    "])\n",
    "\n",
    "dtree_pipeline = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('dtree', dtree)\n",
    "])\n",
    "\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessing', col_transformer),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "# Define hyperparameters and their possible values for each classifier\n",
    "log_reg_params = {'log_reg__C': [0.1, 1, 10], 'log_reg__penalty': ['l1', 'l2']}\n",
    "dtree_params = {'dtree__max_depth': [5, 10, 15], 'dtree__min_samples_split': [2, 5, 10]}\n",
    "rf_params = {'rf__n_estimators': [100, 200, 300], 'rf__max_features': ['auto', 'sqrt']}\n",
    "\n",
    "# Define the number of iterations for each random search\n",
    "n_iter_log_reg = 5\n",
    "n_iter_dtree = 5\n",
    "n_iter_rf = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "25 fits failed out of a total of 25.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 806, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py\", line 699, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 287, in _minimize_lbfgsb\n",
      "    bounds = [(None if l == -np.inf else l, None if u == np.inf else u) for l, u in bounds]\n",
      "  File \"c:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\", line 287, in <listcomp>\n",
      "    bounds = [(None if l == -np.inf else l, None if u == np.inf else u) for l, u in bounds]\n",
      "MemoryError\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nawal\\OneDrive - daiict.ac.in\\Academics\\Semester 7\\IT496 DM\\Labs\\CP 2\\lang_prediction.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nawal/OneDrive%20-%20daiict.ac.in/Academics/Semester%207/IT496%20DM/Labs/CP%202/lang_prediction.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#logistic regression\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nawal/OneDrive%20-%20daiict.ac.in/Academics/Semester%207/IT496%20DM/Labs/CP%202/lang_prediction.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Define the random search for logistic regression\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nawal/OneDrive%20-%20daiict.ac.in/Academics/Semester%207/IT496%20DM/Labs/CP%202/lang_prediction.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m log_reg_random_search \u001b[39m=\u001b[39m RandomizedSearchCV(log_reg_pipeline, log_reg_params, n_iter\u001b[39m=\u001b[39mn_iter_log_reg, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nawal/OneDrive%20-%20daiict.ac.in/Academics/Semester%207/IT496%20DM/Labs/CP%202/lang_prediction.ipynb#X34sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m log_reg_random_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[1;32m--> 394\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\u001b[39m.\u001b[39mfit(Xt, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_last_step)\n\u001b[0;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1461\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1432\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1433\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m \u001b[39m    Fit the model according to the given training data.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[39m    The SAGA solver supports both float64 and float32 bit arrays.\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1461\u001b[0m     solver \u001b[39m=\u001b[39m _check_solver(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msolver, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpenalty, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdual)\n\u001b[0;32m   1463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, numbers\u001b[39m.\u001b[39mNumber) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1464\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mPenalty term must be positive; got (C=\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:447\u001b[0m, in \u001b[0;36m_check_solver\u001b[1;34m(solver, penalty, dual)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    442\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLogistic Regression supports only penalties in \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    443\u001b[0m         \u001b[39m%\u001b[39m (all_penalties, penalty)\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    446\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39msaga\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mand\u001b[39;00m penalty \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 447\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    448\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m supports only \u001b[39m\u001b[39m'\u001b[39m\u001b[39ml2\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m\u001b[39m penalties, got \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m penalty.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    449\u001b[0m         \u001b[39m%\u001b[39m (solver, penalty)\n\u001b[0;32m    450\u001b[0m     )\n\u001b[0;32m    451\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mliblinear\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m dual:\n\u001b[0;32m    452\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSolver \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m supports only dual=False, got dual=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (solver, dual)\n\u001b[0;32m    454\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty."
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "log_reg_random_search = RandomizedSearchCV(log_reg_pipeline, log_reg_params, n_iter=n_iter_log_reg, cv=5, random_state=42)\n",
    "log_reg_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dtree_rand = RandomizedSearchCV(dtree_pipeline, dtree_params, n_iter=n_iter_dtree, cv=5, scoring='accuracy', refit=True, verbose=1)\n",
    "dtree_rand.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rf_rand = RandomizedSearchCV(rf_pipeline, rf_params, n_iter=n_iter_rf, cv=5, scoring='accuracy', refit=True, verbose=1)\n",
    "rf_rand.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "y_pred_log_reg = log_reg_grid.predict(X_test)\n",
    "acc_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "prec_log_reg = precision_score(y_test, y_pred_log_reg, average='macro')\n",
    "rec_log_reg = recall_score(y_test, y_pred_log_reg, average='macro')\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg, average='macro')\n",
    "print('Logistic Regression:')\n",
    "print('Accuracy:', acc_log_reg)\n",
    "print('Precision:', prec_log_reg)\n",
    "print('Recall:', rec_log_reg)\n",
    "print('F1-score:', f1_log_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree\n",
    "acc_dtree = accuracy_score(y_test, y_pred_dtree)\n",
    "y_pred_dtree = dtree_grid.predict(X_test)\n",
    "prec_dtree = precision_score(y_test, y_pred_dtree, average='macro')\n",
    "rec_dtree = recall_score(y_test, y_pred_dtree, average='macro')\n",
    "f1_dtree = f1_score(y_test, y_pred_dtree, average='macro')\n",
    "print('Decision Tree:')\n",
    "print('Accuracy:', acc_dtree)\n",
    "print('Precision:', prec_dtree)\n",
    "print('Recall:', rec_dtree)\n",
    "print('F1-score:', f1_dtree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "y_pred_rf = rf_grid.predict(X_test)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, average='macro')\n",
    "rec_rf = recall_score(y_test, y_pred_rf, average='macro')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "print('Random Forest:')\n",
    "print('Accuracy:', acc_rf)\n",
    "print('Precision:', prec_rf)\n",
    "print('Recall:', rec_rf)\n",
    "print('F1-score:', f1_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "y_pred_knn = knn_grid.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "prec_knn = precision_score(y_test, y_pred_knn, average='macro')\n",
    "rec_knn = recall_score(y_test, y_pred_knn, average='macro')\n",
    "f1_knn = f1_score(y_test, y_pred_knn, average='macro')\n",
    "print('K-Nearest Neighbors:')\n",
    "print('Accuracy:', acc_knn)\n",
    "print('Precision:', prec_knn)\n",
    "print('Recall:', rec_knn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
